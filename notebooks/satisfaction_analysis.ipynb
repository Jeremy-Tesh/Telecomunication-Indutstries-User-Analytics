{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('venv_usr_analytics': venv)"
  },
  "interpreter": {
   "hash": "413b71dc28aac45813ed35103051e8c8dd959175d6292f489eb12ffa988302e4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "engagement score to each user. Consider the engagement score as the Euclidean distance between the user data point & the less engaged cluster (use the first clustering for this)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "sys.path.insert(0, '../scripts')\n",
    "sys.path.insert(0, '../models')\n",
    "import clean_data\n",
    "import utilities\n",
    "import norm_scaling\n",
    "import loading_data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/dibora/User-Analytics-in-the-Telecommunication-Industry/venv_usr_analytics/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  \n",
      "['Start', 'End', 'Last Location Name', 'Handset Manufacturer', 'Handset Type']\n"
     ]
    }
   ],
   "source": [
    "#loaded file\n",
    "df= loading_data.load_csv('../data/data.csv')\n",
    "cleaned_data = clean_data.Handle_missing_values(df,drop_cols=False,drop_rows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our trained kmeans model for user engagement and user experience\n",
    "with open(\"../models/user_engag_model.pkl\", 'rb') as file:  \n",
    "    Pickled_userEngagement_Model = pickle.load(file)\n",
    "with open(\"../models/user_exper_model.pkl\", 'rb') as file:  \n",
    "    Pickled_userExperience_Model = pickle.load(file)   \n"
   ]
  },
  {
   "source": [
    "To calculate the euclidean distance between each datapoint and the less engaged user cluster we will use the centroid of cluster 0 and each normalized user data points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.11979774, 0.01099528, 0.11897878, 0.12120409]),\n",
       " array([0.00089951, 0.00530876, 0.00801262, 0.01002238, 0.27762946,\n",
       "        0.00103293]))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#the center for the first cluster\n",
    "engagement_cluster0_center = Pickled_userEngagement_Model.cluster_centers_[0,:]\n",
    "experience_cluster0_center = Pickled_userExperience_Model.cluster_centers_[1,:]\n",
    "engagement_cluster0_center,experience_cluster0_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we take the datapoints for the appropriate user engagement metrics  \n",
    "cleaned_copy = cleaned_data.copy()\n",
    "df_user = cleaned_copy.groupby(\"MSISDN/Number\")\n",
    "\n",
    "\n",
    "df_session_freq = pd.DataFrame(df_user[\"Bearer Id\"].count())\n",
    "df_session_dur = pd.DataFrame(df_user[\"Dur. (ms)\"].sum())\n",
    "df_session_UL = pd.DataFrame(df_user[\"Total UL (Bytes)\"].sum())\n",
    "df_session_DL = pd.DataFrame(df_user[\"Total DL (Bytes)\"].sum())\n",
    "\n",
    "df_RTT_DL = pd.DataFrame(df_user[\"Avg RTT DL (ms)\"].sum())\n",
    "df_RTT_UL = pd.DataFrame(df_user[\"Avg RTT UL (ms)\"].sum())\n",
    "df_TP_DL = pd.DataFrame(df_user[\"Avg Bearer TP DL (kbps)\"].sum())\n",
    "df_TP_UL = pd.DataFrame(df_user[\"Avg Bearer TP UL (kbps)\"].sum())\n",
    "df_TCP_DL = pd.DataFrame(df_user[\"TCP DL Retrans. Vol (Bytes)\"].sum())\n",
    "df_TCP_UL = pd.DataFrame(df_user[\"TCP UL Retrans. Vol (Bytes)\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize them \n",
    "normalized_data_freq = norm_scaling.normalize(df_session_freq)\n",
    "normalized_data_dur = norm_scaling.normalize(df_session_dur)\n",
    "normalized_data_UL = norm_scaling.normalize(df_session_DL)\n",
    "normalized_data_DL = norm_scaling.normalize(df_session_UL)\n",
    "\n",
    "normalized_RTT_DL = norm_scaling.normalize(df_RTT_DL)\n",
    "normalized_RTT_UL = norm_scaling.normalize(df_RTT_UL)\n",
    "normalized_TP_DL = norm_scaling.normalize(df_TP_DL)\n",
    "normalized_TP_UL = norm_scaling.normalize(df_TP_UL)\n",
    "normalized_TCP_DL = norm_scaling.normalize(df_TCP_DL)\n",
    "normalized_TCP_UL = norm_scaling.normalize(df_TCP_UL)\n",
    "\n",
    "\n",
    "X_engag = np.hstack((normalized_data_freq,normalized_data_dur,normalized_data_DL,normalized_data_UL))\n",
    "X_exper = np.hstack((normalized_RTT_DL,normalized_RTT_UL,normalized_TP_DL,normalized_TP_UL,normalized_TCP_DL,normalized_TCP_UL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                           user_id  satisfaction_score\n",
       " MSISDN/Number                                         \n",
       " 33,663,706,799.00  [33663706799.0]                1.97\n",
       " 33,669,054,076.00  [33669054076.0]                0.62\n",
       " 33,658,249,284.00  [33658249284.0]                0.39\n",
       " 33,763,588,772.00  [33763588772.0]                0.38\n",
       " 33,667,725,464.00  [33667725464.0]                0.36\n",
       " 33,659,084,281.00  [33659084281.0]                0.34\n",
       " 33,659,778,586.00  [33659778586.0]                0.33\n",
       " 33,662,317,023.00  [33662317023.0]                0.32\n",
       " 33,665,090,461.00  [33665090461.0]                0.32\n",
       " 33,664,698,321.00  [33664698321.0]                0.31,\n",
       " array([0.24228107, 0.24269073, 0.24242186, ..., 0.24254936, 0.24228781,\n",
       "        0.24247019]))"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# calculate satisfaction score \n",
    "engagement_score= euclidean_distances(X_engag,engagement_cluster0_center.reshape(1, -1))\n",
    "experience_score= euclidean_distances(X_exper,experience_cluster0_center.reshape(1, -1))\n",
    "satisfaction_score = ((engagement_score+experience_score)/2).flatten()\n",
    "df_user_score = pd.DataFrame({\"user_id\":df_user[\"MSISDN/Number\"].unique(),\"satisfaction_score\":satisfaction_score}).sort_values(by=\"satisfaction_score\",ascending=False).head(10)\n",
    "\n",
    "df_user_score,satisfaction_score\n",
    "\n"
   ]
  },
  {
   "source": [
    "Build a regression model of your choice to predict the satisfaction score of a customer. To build satisfaction score we will take all engagement and experience analysis metrics. So since we have a continous type y, we will use a simple linear regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X_engag,X_exper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(X, satisfaction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2.53073228, -0.30941127, -0.1129131 , -0.21050975,  0.27175037,\n",
       "        0.08032218, -0.29057944, -0.07060393, -0.29852672,  0.30356674])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "source": [
    "Kmeans(k=2) on engagement and experience scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "X_scores = np.hstack((engagement_score,experience_score))\n",
    "X_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(X_scores)\n",
    "pickle.dump(kmeans, open(\"../models/scores_model.pkl\", 'wb'))\n",
    "kmeans_pred = kmeans.predict(X_scores)"
   ]
  },
  {
   "source": [
    "Aggregate the average satisfaction & experience score per cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect each score values in each cluster\n",
    "cluster_no = 2\n",
    "clusters = {}\n",
    "container_eng = []\n",
    "container_exp = []\n",
    "for i in range(0,cluster_no):\n",
    "    for x_eng,x_exp,y in zip(X_scores[:,0],X_scores[:,1],kmeans_pred):    \n",
    "        if y == i:\n",
    "            container_eng.append(x_eng)\n",
    "            container_exp.append(x_exp)\n",
    "    clusters[\"cluster_\"+str(i)] = {\"engagement_scores\":np.array(container_eng),\"experience_scores\":np.array(container_exp)}\n",
    "    container_eng = []\n",
    "    container_exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n106567\ncluster 0,avg of engagement_scores 0.20641571458435432\n106567\ncluster 0,avg of experience_scores 0.2774985875307438\n289\ncluster 1,avg of engagement_scores 0.20491321865085432\n289\ncluster 1,avg of experience_scores 0.09849401879379184\n"
     ]
    }
   ],
   "source": [
    "#calculate the average scores of each cluster\n",
    "score_names = [\"engagement_scores\",\"experience_scores\"]\n",
    "scores = 2\n",
    "print()\n",
    "for i in range(2):\n",
    "    for score in range(0,scores):\n",
    "        data_cluster = clusters[\"cluster_\"+str(i)][score_names[score]]\n",
    "        print(len(data_cluster))\n",
    "        print(\"cluster \"+str(i)+ \",avg of \"+score_names[score],data_cluster.mean())\n"
   ]
  },
  {
   "source": [
    "Export your final table containing all user id + engagement, experience & satisfaction scores in your local MySQL database. Report a screenshot of a select query output on the exported table. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            user_id  engagement_score  experience_score  satisfaction_score\n",
      "0 33,601,001,722.00              0.09              0.28                0.19\n",
      "1 33,601,001,754.00              0.09              0.28                0.19\n",
      "2 33,601,002,511.00              0.09              0.28                0.19\n",
      "3 33,601,007,832.00              0.09              0.28                0.19\n",
      "4 33,601,008,617.00              0.09              0.28                0.18\n",
      "5 33,601,010,682.00              0.09              0.28                0.19\n",
      "6 33,601,011,634.00              0.09              0.28                0.19\n",
      "7 33,601,011,959.00              0.09              0.28                0.19\n",
      "8 33,601,014,694.00              0.09              0.28                0.19\n",
      "9 33,601,020,306.00              0.09              0.28                0.19\n",
      "File Successfully Saved.!!!\n"
     ]
    }
   ],
   "source": [
    "# prepare a dataframe with user_id, engagement_score, experience_score and satisfaction_score\n",
    "df_scores = pd.DataFrame({\"user_id\":df_user[\"MSISDN/Number\"].groups.keys(),\"engagement_score\":engagement_score.flatten().astype(np.float64),\"experience_score\":experience_score.flatten(),\"satisfaction_score\":satisfaction_score})\n",
    "print(df_scores.head(10))\n",
    "\n",
    "# save this dataframe to the database\n",
    "df_scores.to_csv('../data/user_data_scores.csv', index=False)\n",
    "print('File Successfully Saved.!!!')"
   ]
  },
  {
   "source": [
    "Task 4.7 Model deployment tracking- deploy the model and monitor your model. Here you can use Docker or other MlOps tools which can help you to track your modelâ€™s change.  Your model tracking report includes code version, start and end time, source, parameters, metrics (loss convergence) and artifacts or any output file regarding each specific run. (CSV file, screenshot)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}