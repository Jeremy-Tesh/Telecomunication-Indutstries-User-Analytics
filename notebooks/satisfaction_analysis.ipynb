{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('venv_usr_analytics': venv)"
  },
  "interpreter": {
   "hash": "413b71dc28aac45813ed35103051e8c8dd959175d6292f489eb12ffa988302e4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "engagement score to each user. Consider the engagement score as the Euclidean distance between the user data point & the less engaged cluster (use the first clustering for this)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "sys.path.insert(0, '../scripts')\n",
    "sys.path.insert(0, '../models')\n",
    "import clean_data\n",
    "import utilities\n",
    "import norm_scaling\n",
    "import loading_data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/dibora/User-Analytics-in-the-Telecommunication-Industry/venv_usr_analytics/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  \n",
      "['Start', 'End', 'Last Location Name', 'Handset Manufacturer', 'Handset Type']\n"
     ]
    }
   ],
   "source": [
    "#loaded file\n",
    "df= loading_data.load_csv('../data/data.csv')\n",
    "cleaned_data = clean_data.Handle_missing_values(df,drop_cols=False,drop_rows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our trained kmeans model for user engagement and user experience\n",
    "with open(\"../models/user_engag_model.pkl\", 'rb') as file:  \n",
    "    Pickled_userEngagement_Model = pickle.load(file)\n",
    "with open(\"../models/user_exper_model.pkl\", 'rb') as file:  \n",
    "    Pickled_userExperience_Model = pickle.load(file)   \n"
   ]
  },
  {
   "source": [
    "To calculate the euclidean distance between each datapoint and the less engaged user cluster we will use the centroid of cluster 0 and each normalized user data points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.11979774, 0.01099528, 0.11897878, 0.12120409]),\n",
       " array([0.00089951, 0.00530876, 0.00801262, 0.01002238, 0.27762946,\n",
       "        0.00103293]))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#the center for the first cluster\n",
    "engagement_cluster0_center = Pickled_userEngagement_Model.cluster_centers_[0,:]\n",
    "experience_cluster0_center = Pickled_userExperience_Model.cluster_centers_[1,:]\n",
    "engagement_cluster0_center,experience_cluster0_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we take the datapoints for the appropriate user engagement metrics  \n",
    "cleaned_copy = cleaned_data.copy()\n",
    "df_user = cleaned_copy.groupby(\"MSISDN/Number\")\n",
    "\n",
    "\n",
    "df_session_freq = pd.DataFrame(df_user[\"Bearer Id\"].count())\n",
    "df_session_dur = pd.DataFrame(df_user[\"Dur. (ms)\"].sum())\n",
    "df_session_UL = pd.DataFrame(df_user[\"Total UL (Bytes)\"].sum())\n",
    "df_session_DL = pd.DataFrame(df_user[\"Total DL (Bytes)\"].sum())\n",
    "\n",
    "df_RTT_DL = pd.DataFrame(df_user[\"Avg RTT DL (ms)\"].sum())\n",
    "df_RTT_UL = pd.DataFrame(df_user[\"Avg RTT UL (ms)\"].sum())\n",
    "df_TP_DL = pd.DataFrame(df_user[\"Avg Bearer TP DL (kbps)\"].sum())\n",
    "df_TP_UL = pd.DataFrame(df_user[\"Avg Bearer TP UL (kbps)\"].sum())\n",
    "df_TCP_DL = pd.DataFrame(df_user[\"TCP DL Retrans. Vol (Bytes)\"].sum())\n",
    "df_TCP_UL = pd.DataFrame(df_user[\"TCP UL Retrans. Vol (Bytes)\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize them \n",
    "normalized_data_freq = norm_scaling.normalize(df_session_freq)\n",
    "normalized_data_dur = norm_scaling.normalize(df_session_dur)\n",
    "normalized_data_UL = norm_scaling.normalize(df_session_DL)\n",
    "normalized_data_DL = norm_scaling.normalize(df_session_UL)\n",
    "\n",
    "normalized_RTT_DL = norm_scaling.normalize(df_RTT_DL)\n",
    "normalized_RTT_UL = norm_scaling.normalize(df_RTT_UL)\n",
    "normalized_TP_DL = norm_scaling.normalize(df_TP_DL)\n",
    "normalized_TP_UL = norm_scaling.normalize(df_TP_UL)\n",
    "normalized_TCP_DL = norm_scaling.normalize(df_TCP_DL)\n",
    "normalized_TCP_UL = norm_scaling.normalize(df_TCP_UL)\n",
    "\n",
    "\n",
    "X_engag = np.hstack((normalized_data_freq,normalized_data_dur,normalized_data_DL,normalized_data_UL))\n",
    "X_exper = np.hstack((normalized_RTT_DL,normalized_RTT_UL,normalized_TP_DL,normalized_TP_UL,normalized_TCP_DL,normalized_TCP_UL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                           user_id  satisfaction_score\n",
       " MSISDN/Number                                         \n",
       " 33,663,706,799.00  [33663706799.0]                1.97\n",
       " 33,669,054,076.00  [33669054076.0]                0.62\n",
       " 33,658,249,284.00  [33658249284.0]                0.39\n",
       " 33,763,588,772.00  [33763588772.0]                0.38\n",
       " 33,667,725,464.00  [33667725464.0]                0.36\n",
       " 33,659,084,281.00  [33659084281.0]                0.34\n",
       " 33,659,778,586.00  [33659778586.0]                0.33\n",
       " 33,662,317,023.00  [33662317023.0]                0.32\n",
       " 33,665,090,461.00  [33665090461.0]                0.32\n",
       " 33,664,698,321.00  [33664698321.0]                0.31,\n",
       " array([0.24228107, 0.24269073, 0.24242186, ..., 0.24254936, 0.24228781,\n",
       "        0.24247019]))"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# calculate satisfaction score \n",
    "engagement_score= euclidean_distances(X_engag,engagement_cluster0_center.reshape(1, -1))\n",
    "experience_score= euclidean_distances(X_exper,experience_cluster0_center.reshape(1, -1))\n",
    "satisfaction_score = ((engagement_score+experience_score)/2).flatten()\n",
    "df_user_score = pd.DataFrame({\"user_id\":df_user[\"MSISDN/Number\"].unique(),\"satisfaction_score\":satisfaction_score}).sort_values(by=\"satisfaction_score\",ascending=False).head(10)\n",
    "\n",
    "df_user_score,satisfaction_score\n",
    "\n"
   ]
  },
  {
   "source": [
    "Build a regression model of your choice to predict the satisfaction score of a customer. To build satisfaction score we will take all engagement and experience analysis metrics. So since we have a continous type y, we will use a simple linear regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X_engag,X_exper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(X, satisfaction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2.53073228, -0.30941127, -0.1129131 , -0.21050975,  0.27175037,\n",
       "        0.08032218, -0.29057944, -0.07060393, -0.29852672,  0.30356674])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "source": [
    "Kmeans(k=2) on engagement and experience scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "X_scores = np.hstack((engagement_score,experience_score))\n",
    "X_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(X_scores)\n",
    "pickle.dump(kmeans, open(\"../models/scores_model.pkl\", 'wb'))\n",
    "kmeans_pred = kmeans.predict(X_scores)"
   ]
  },
  {
   "source": [
    "Aggregate the average satisfaction & experience score per cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect each score values in each cluster\n",
    "cluster_no = 2\n",
    "clusters = {}\n",
    "container_eng = []\n",
    "container_exp = []\n",
    "for i in range(0,cluster_no):\n",
    "    for x_eng,x_exp,y in zip(X_scores[:,0],X_scores[:,1],kmeans_pred):    \n",
    "        if y == i:\n",
    "            container_eng.append(x_eng)\n",
    "            container_exp.append(x_exp)\n",
    "    clusters[\"cluster_\"+str(i)] = {\"engagement_scores\":np.array(container_eng),\"experience_scores\":np.array(container_exp)}\n",
    "    container_eng = []\n",
    "    container_exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n106567\ncluster 0,avg of engagement_scores 0.20641571458435432\n106567\ncluster 0,avg of experience_scores 0.2774985875307438\n289\ncluster 1,avg of engagement_scores 0.20491321865085432\n289\ncluster 1,avg of experience_scores 0.09849401879379184\n"
     ]
    }
   ],
   "source": [
    "#calculate the average scores of each cluster\n",
    "score_names = [\"engagement_scores\",\"experience_scores\"]\n",
    "scores = 2\n",
    "print()\n",
    "for i in range(2):\n",
    "    for score in range(0,scores):\n",
    "        data_cluster = clusters[\"cluster_\"+str(i)][score_names[score]]\n",
    "        print(len(data_cluster))\n",
    "        print(\"cluster \"+str(i)+ \",avg of \"+score_names[score],data_cluster.mean())\n"
   ]
  },
  {
   "source": [
    "Export your final table containing all user id + engagement, experience & satisfaction scores in your local MySQL database. Report a screenshot of a select query output on the exported table. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            user_id  engagement_score  experience_score  satisfaction_score\n",
      "0 33,601,001,722.00              0.09              0.28                0.19\n",
      "1 33,601,001,754.00              0.09              0.28                0.19\n",
      "2 33,601,002,511.00              0.09              0.28                0.19\n",
      "3 33,601,007,832.00              0.09              0.28                0.19\n",
      "4 33,601,008,617.00              0.09              0.28                0.18\n",
      "5 33,601,010,682.00              0.09              0.28                0.19\n",
      "6 33,601,011,634.00              0.09              0.28                0.19\n",
      "7 33,601,011,959.00              0.09              0.28                0.19\n",
      "8 33,601,014,694.00              0.09              0.28                0.19\n",
      "9 33,601,020,306.00              0.09              0.28                0.19\n",
      "File Successfully Saved.!!!\n"
     ]
    }
   ],
   "source": [
    "# prepare a dataframe with user_id, engagement_score, experience_score and satisfaction_score\n",
    "df_scores = pd.DataFrame({\"user_id\":df_user[\"MSISDN/Number\"].groups.keys(),\"engagement_score\":engagement_score.flatten().astype(np.float64),\"experience_score\":experience_score.flatten(),\"satisfaction_score\":satisfaction_score})\n",
    "print(df_scores.head(10))\n",
    "\n",
    "# save this dataframe to the database\n",
    "df_scores.to_csv('../data/user_data_scores.csv', index=False)\n",
    "print('File Successfully Saved.!!!')"
   ]
  },
  {
   "source": [
    "Task 4.7 Model deployment tracking- deploy the model and monitor your model. Here you can use Docker or other MlOps tools which can help you to track your model’s change.  Your model tracking report includes code version, start and end time, source, parameters, metrics (loss convergence) and artifacts or any output file regarding each specific run. (CSV file, screenshot)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}